@STRING{aaai    = {Proc. {AAAI}} }
@STRING{acc     = {Proc. {ACC}} }
@STRING{accv    = {Proc. {ACCV}} }
@STRING{acmmm   = {Proc. {ACMM}} }
@STRING{add     = {Addison-Wesley} }
@STRING{ai      = {Artificial Intelligence} }
@STRING{aistats = {Proc. {AISTATS}} }
@STRING{aiuws   = {Arpa Image Understanding Workshop} }
@STRING{arxiv   = {arXiv} }
@STRING{avc     = {Proc. {Alvey Vision Conf.}} }
@STRING{bmvc    = {Proc. {BMVC}} }
@STRING{cdc     = {Proc. {Decision and Control}} }
@STRING{civr    = {Proc. {CIVR}} }
@STRING{cmpb    = {Computer Methods and Programs in Biomedicine} }
@STRING{commacm = {Commun. {ACM}} }
@STRING{compj   = {Computer Journal} }
@STRING{corr    = {arXiv.cs} }
@STRING{cup     = {Cambridge University Press} }
@STRING{cvgip   = {Computer Vision, Graphics and Image Processing} }
@STRING{cvgipiu = {{CVGIP}: Image Understanding} }
@STRING{cviu    = {CVIU} }
@STRING{cvpr    = {Proc. {CVPR}} }
@STRING{cvprw   = {Proc. {CVPR} Workshops} }
@STRING{dagm    = {Proc. {DAGM}} }
@STRING{eccv    = {Proc. {ECCV}} }
@STRING{eccvw   = {Proc. {ECCV} Workshops} }
@STRING{ecml    = {Proc. {ECML}} }
@STRING{fg      = {Proc. {Autom. Face and Gesture Recog.}} }
@STRING{icann   = {Proc. {ICANN}} }
@STRING{icarcv  = {Proc. {Automation, Robotics and Computer Vision}} }
@STRING{icassp  = {Proc. ICASSP} }
@STRING{iccv    = {Proc. {ICCV}} }
@STRING{iccvw   = {Proc. {ICCV} Workshops} }
@STRING{iciap   = {Proc. {ICIAP}} }
@STRING{icip    = {Proc. {ICIP}} }
@STRING{iclr    = {Proc. {ICLR}} }
@STRING{iclrw   = {Proc. {ICLR} Workshops} }
@STRING{icml    = {Proc. {ICML}} }
@STRING{icmr    = {Proc. {ICMR}} }
@STRING{icpr    = {Proc. {ICPR}} }
@STRING{icra    = {Proc. {ICRA}} }
@STRING{icvgip  = {Proc. {ICVGIP}} }
@STRING{icwi    = {Proc. {ICWI}} }
@STRING{ijcai   = {Proc. {IJCAI}} }
@STRING{ijcv    = {{IJCV}} }
@STRING{ijmi    = {Intl. J. {Medical Informatics}} }
@STRING{ijprai  = {Intl. J. of {Patt. Recogn. in Artificial Intelligence}} }
@STRING{ijrr    = {Intl. J. of {Robotics Research}} }
@STRING{inria   = {{INRIA}} }
@STRING{iros    = {Proc.{IROS}} }
@STRING{iscv    = {IEEE Intl. Symposium on Computer Vision} }
@STRING{ismi    = {Proc. {ISMI}} }
@STRING{isrr    = {Proc. {ISCV}} }
@STRING{iuw     = {Proc. {DARPA Image Understanding Workshop}} }
@STRING{ivc     = {Image and Vision Computing} }
@STRING{jmiv    = {J. Math. Imaging and Vision} }
@STRING{jmlr    = {{JMLR}} }
@STRING{josa    = {J. of the {Optical Society of America}} }
@STRING{jra     = {{IEEE} J. of {Robotics and Automation}} }
@STRING{jvcir   = {J. of {Visual Communication and Image Representation}} }
@STRING{kdd     = {Proc. {KDD}} }
@STRING{kluw    = {Kluwer Academic Publishers} }
@STRING{lncs    = {LNCS} }
@STRING{mcbr    = {Proc. {MCBR-CDS}} }
@STRING{miccai  = {Proc. {MICCAI}} }
@STRING{mit     = {{MIT}} }
@STRING{mitai   = {{MIT} Artificial Intelligence Laboratory} }
@STRING{mmbia   = {Proc. {MMBIA}} }
@STRING{mprog   = {{Math. Prog.}} }
@STRING{mva     = {Machine Vision and Applications} }
@STRING{nips    = {Proc. {NeurIPS}} }
@STRING{oueng   = {Dept. of Engineering Science, University of Oxford} }
@STRING{oup     = {Oxford University Press} }
@STRING{pieee   = {Proceedings of IEEE} }
@STRING{pnas    = {Proc. Nat. Acad. Sci. USA} }
@STRING{prl     = {Pattern Recognition Letters} }
@STRING{prsl    = {Proc. of the Royal Society of London} }
@STRING{ptrsla  = {Phil. Trans. R. Soc. Lond. A} }
@STRING{ptrslb  = {Phil. Trans. R. Soc. Lond. B} }
@STRING{ra      = {Proc. {Robotics and Automation}} }
@STRING{royalstat={Journal of the Royal Statistical Society} }
@STRING{rs      = {Proc. {Royal Society}} }
@STRING{sibgraph= {Proc. {SIBGRAPH}} }
@STRING{siggraph= {Proc. {SIGGRAPH}} }
@STRING{sigir   = {Proc. {SIGIR}} }
@STRING{sp      = {Springer-Verlag} }
@STRING{spie    = {SPIE Conferences} }
@STRING{spm     = {{IEEE} Signal Proc. Mag.} }
@STRING{stoc    = {Proc. {Symposium on Theory of Computing}} }
@STRING{tcomputer={{IEEE} Trans. on Computers} }
@STRING{tcsvt   = {IEEE Trans. Circuits and Systems for Video Technology} }
@STRING{texture = {Proc. Intl. Workshop on {Texture Analysis and Synthesis}} }
@STRING{threedim= {Proc. {3DIM}} }
@STRING{threedv = {Proc. {3DV}} }
@STRING{tinft   = {{IEEE} Trans. on Information Theory} }
@STRING{tip     = {{IEEE} Trans. on Image Processing} }
@STRING{tist    = {{ACM} {TIST}} }
@STRING{tit     = {{IEEE} Trans. on {Information Theory}} }
@STRING{tmi     = {{IEEE} TMI} }
@STRING{tnn     = {{IEEE} Trans. Neural Networks} }
@STRING{tog     = {ACM Trans. on Graphics (TOG)} }
@STRING{tpami   = {{PAMI}} }
@STRING{tra     = {{IEEE} Trans. Robotics and Automation} }
@STRING{tsp     = {{IEEE} Trans. on Signal Processing} }
@STRING{visalgs = {Vision Algorithms: Theory and Practice} }
@STRING{wacv    = {Proc. {WACV}} }
@STRING{wil     = {John Wiley and Sons} }

@inproceedings{novotny2015cascaded,
  title={Cascaded sparse spatial bins for efficient and effective generic object detection},
  author={Novotny, David and Matas, Jiri},
  booktitle=iccv,
  pages={1152--1160},
  year={2015},
}

@inproceedings{novotny2016ihave,
  title={I have seen enough: Transferring parts across categories},
  author={Novotny, David and Larlus, Diane and Vedaldi, Andrea},
  booktitle=bmvc,
  year={2016},
  project_page={http://www.robots.ox.ac.uk/~vgg/data/animal_parts/},
}

@inproceedings{novotny2016learning,
  title={Learning the structure of objects from web supervision},
  author={Novotny, David and Larlus, Diane and Vedaldi, Andrea},
  booktitle=eccvw,
  pages={218--235},
  year={2016},
  organization={Springer International Publishing}
}

@inproceedings{novotny2017anchornet,
  title={AnchorNet: A Weakly Supervised Network to Learn Geometry-sensitive Features For Semantic Matching},
  author={Novotny, David and Larlus, Diane and Vedaldi, Andrea},
  booktitle=cvpr,
  year={2017},
  code={code/anchornet_code_v0.1.zip}
}

@inproceedings{novotny2017learning,
  title={Learning 3D Object Categories by Looking Around Them},
  author={Novotny, David and Larlus, Diane and Vedaldi, Andrea},
  booktitle=iccv,
  year={2017},
  talk={https://www.youtube.com/watch?v=esYBbQuKFZU&t=}
}

@inproceedings{novotny2018self,
  title={Self-supervised learning of geometrically stable features through probabilistic introspection},
  author={Novotny, David and Albanie, Samuel and Larlus, Diane and Vedaldi, Andrea},
  booktitle=cvpr,
  pages={3637--3645},
  year={2018},
  talk={https://www.facebook.com/CVPR2018/videos/1994396307555935/},
  note={spotlight presentation}
}


@inproceedings{novotny2018semi,
  title={Semi-convolutional operators for instance segmentation},
  author={Novotny, David and Albanie, Samuel and Larlus, Diane and Vedaldi, Andrea},
  booktitle=eccv,
  pages={86--102},
  year={2018}
}

@article{novotny2018capturing,
  title={Capturing the geometry of object categories from video supervision},
  author={Novotny, David and Larlus, Diane and Vedaldi, Andrea},
  journal=tpami,
  volume={42},
  number={2},
  pages={261--275},
  year={2018},
  publisher={IEEE},
  is_gif_thumb={true}
}

@inproceedings{novotny2019c3dpo,
  title={C3dpo: Canonical 3d pose networks for non-rigid structure from motion},
  author={Novotny, David and Ravi, Nikhila and Graham, Benjamin and Neverova, Natalia and Vedaldi, Andrea},
  booktitle=iccv,
  pages={7688--7697},
  year={2019},
  code={https://github.com/facebookresearch/c3dpo_nrsfm},
  talk={https://youtu.be/zem03fZWLrQ?t=2303},
  is_gif_thumb={true}
}

@inproceedings{novotny2019perspectivenet,
  title={PerspectiveNet: A Scene-consistent Image Generator for New View Synthesis in Real Indoor Environments},
  author={Novotny, David and Graham, Ben and Reizenstein, Jeremy},
  booktitle=nips,
  pages={7599--7610},
  year={2019}
}

@article{neverova2019correlated,
  title={Correlated uncertainty for learning dense correspondences from noisy labels},
  author={Neverova, Natalia and Novotny, David and Vedaldi, Andrea},
  journal=nips,
  volume={32},
  year={2019},
  link={https://proceedings.neurips.cc/paper_files/paper/2019/file/53fde96fcc4b4ce72d7739202324cd49-Paper.pdf},
}

@article{ravi2020accelerating,
  title={Accelerating 3d deep learning with pytorch3d},
  author={Ravi, Nikhila and Reizenstein, Jeremy and Novotny, David and Gordon, Taylor and Lo, Wan-Yen and Johnson, Justin and Gkioxari, Georgia},
  journal=arxiv,
  year={2020},
  link={https://arxiv.org/pdf/2007.08501},
}

@article{novotny2020c3dm,
  title={Canonical 3D Deformer Maps: Unifying parametric and non-parametric methods for dense weakly-supervised category reconstruction},
  author={Novotny, David and Shapovalov, Roman and Vedaldi, Andrea},
  journal=nips,
  volume={33},
  pages={20901--20912},
  year={2020},
  code={https://github.com/facebookresearch/c3dm}
}

@article{biggs20203dmulti,
  title={3d multi-bodies: Fitting sets of plausible 3d human models to ambiguous image data},
  author={Biggs, Benjamin and Ehrhardt, Sebastien and Joo, Hanbyul and Graham, Ben and Vedaldi, Andrea and Novotny, David},
  journal=nips,
  volume={33},
  pages={20496--20507},
  year={2020},
  talk={https://youtu.be/uSvswzbQ-Q8},
  projectpage={https://sites.google.com/view/3dmb/home},
  note={spotlight presentation},
}

@article{neverova2020continuous,
  title={Continuous surface embeddings},
  author={Neverova, Natalia and Novotny, David and Szafraniec, Marc and Khalidov, Vasil and Labatut, Patrick and Vedaldi, Andrea},
  journal=nips,
  volume={33},
  pages={17258--17270},
  year={2020},
  link={https://arxiv.org/pdf/2011.12438},
}

@inproceedings{graham2020ridgesfm,
  title={RidgeSfM: Structure from motion via robust pairwise matching under depth uncertainty},
  author={Graham, Benjamin and Novotny, David},
  booktitle=threedv,
  pages={652--662},
  year={2020},
  organization={IEEE},
  code={https://github.com/facebookresearch/RidgeSfM}
}

@inproceedings{henzler2021unsupervised,
  title={Unsupervised learning of 3d object categories from videos in the wild},
  author={Henzler, Philipp and Reizenstein, Jeremy and Labatut, Patrick and Shapovalov, Roman and Ritschel, Tobias and Vedaldi, Andrea and Novotny, David},
  booktitle=cvpr,
  pages={4700--4709},
  year={2021},
  talk={https://youtu.be/910z84dldEU}
}

@inproceedings{eisenberger2021neuromorph,
  title={Neuromorph: Unsupervised shape interpolation and correspondence in one go},
  author={Eisenberger, Marvin and Novotny, David and Kerchenbaum, Gael and Labatut, Patrick and Neverova, Natalia and Cremers, Daniel and Vedaldi, Andrea},
  booktitle=cvpr,
  pages={7473--7483},
  year={2021},
  is_gif_thumb={true},
}

@inproceedings{neverova2021discovering,
  title={Discovering relationships between object categories via universal canonical maps},
  author={Neverova, Natalia and Sanakoyeu, Artsiom and Labatut, Patrick and Novotny, David and Vedaldi, Andrea},
  booktitle=cvpr,
  pages={404--413},
  year={2021},
  link={https://arxiv.org/pdf/2106.09758},
}

@article{atzmon2021augmenting,
  title={Augmenting implicit neural shape representations with explicit deformation fields},
  author={Atzmon, Matan and Novotny, David and Vedaldi, Andrea and Lipman, Yaron},
  journal=arxiv,
  year={2021},
  link={https://arxiv.org/abs/2108.08931},
}

@inproceedings{reizenstein2021co3d,
  title={Common objects in 3d: Large-scale learning and evaluation of real-life 3d category reconstruction},
  author={Reizenstein, Jeremy and Shapovalov, Roman and Henzler, Philipp and Sbordone, Luca and Labatut, Patrick and Novotny, David},
  booktitle=iccv,
  pages={10901--10911},
  year={2021},
  note={Oral presentation},
  extranote={Best Paper Honorable Mention},
  code={https://github.com/facebookresearch/co3d},
  projectpage={https://ai.facebook.com/datasets/CO3D-dataset/},
  talk={https://www.youtube.com/watch?v=hMx9nzG50xQ}
}

@inproceedings{shapovalov2021densepose,
  title={DensePose 3D: Lifting canonical surface maps of articulated objects to the third dimension},
  author={Shapovalov, Roman and Novotny, David and Graham, Benjamin and Labatut, Patrick and Vedaldi, Andrea},
  booktitle=iccv,
  pages={11729--11739},
  year={2021},
  note={Oral presentation},
  link={https://arxiv.org/pdf/2109.00033},
}

@article{ortiz2022isdf,
  title={isdf: Real-time neural signed distance fields for robot perception},
  author={Ortiz, Joseph and Clegg, Alexander and Dong, Jing and Sucar, Edgar and Novotny, David and Zollhoefer, Michael and Mukadam, Mustafa},
  journal=arxiv,
  year={2022},
  code={https://github.com/facebookresearch/iSDF},
  projectpage={https://joeaortiz.github.io/iSDF/},
  talk={https://www.youtube.com/watch?v=mAKGl1wBSic&ab_channel=JosephOrtiz},
  link={https://arxiv.org/pdf/2204.02296},
}

@inproceedings{germain2022feature,
  title={Feature query networks: Neural surface description for camera pose refinement},
  author={Germain, Hugo and DeTone, Daniel and Pascoe, Geoffrey and Schmidt, Tanner and Novotny, David and Newcombe, Richard and Sweeney, Chris and Szeliski, Richard and Balntas, Vasileios},
  booktitle=cvprw,
  pages={5071--5081},
  year={2022},
  link={https://openaccess.thecvf.com/content/CVPR2022W/IMW/papers/Germain_Feature_Query_Networks_Neural_Surface_Description_for_Camera_Pose_Refinement_CVPRW_2022_paper.pdf},
}

@inproceedings{novotny2022keytr,
  title={Keytr: Keypoint transporter for 3d reconstruction of deformable objects in videos},
  author={Novotny, David and Rocco, Ignacio and Sinha, Samarth and Carlier, Alexandre and Kerchenbaum, Gael and Shapovalov, Roman and Smetanin, Nikita and Neverova, Natalia and Graham, Benjamin and Vedaldi, Andrea},
  booktitle=cvpr,
  pages={5595--5604},
  year={2022},
  link={https://www.robots.ox.ac.uk/~vedaldi/assets/pubs/novotny22keypoint.pdf},
}

@inproceedings{sinha2023common,
  title={Common pets in 3d: Dynamic new-view synthesis of real-life deformable categories},
  author={Sinha, Samarth and Shapovalov, Roman and Reizenstein, Jeremy and Rocco, Ignacio and Neverova, Natalia and Vedaldi, Andrea and Novotny, David},
  booktitle=cvpr,
  pages={4881--4891},
  year={2023},
  link={https://arxiv.org/pdf/2211.03889},
  code={https://github.com/facebookresearch/cop3d},
  projectpage={https://cop3d.github.io/},
}

@inproceedings{el2023self,
  title={Self-supervised correspondence estimation via multiview registration},
  author={El Banani, Mohamed and Rocco, Ignacio and Novotny, David and Vedaldi, Andrea and Neverova, Natalia and Johnson, Justin and Graham, Ben},
  booktitle=wacv,
  pages={1216--1225},
  year={2023},
  code={https://github.com/facebookresearch/SyncMatch},
  projectpage={https://mbanani.github.io/syncmatch/},
  link={https://arxiv.org/pdf/2212.03236},
}


@article{rocco2023real,
  title={Real-time volumetric rendering of dynamic humans},
  author={Rocco, Ignacio and Makarov, Iurii and Kokkinos, Filippos and Novotny, David and Graham, Benjamin and Neverova, Natalia and Vedaldi, Andrea},
  journal=arxiv,
  year={2023},
  projectpage={https://real-time-humans.github.io/},
  link={https://arxiv.org/abs/2303.11898},
}

@inproceedings{karnewar2023holodiffusion,
  title={Holodiffusion: Training a 3d diffusion model using 2d images},
  author={Karnewar, Animesh and Vedaldi, Andrea and Novotny, David and Mitra, Niloy J},
  booktitle=cvpr,
  pages={18423--18433},
  year={2023},
  link={https://holodiffusion.github.io/static/docs/holo_diffusion_fullres.pdf},
  projectpage={https://holodiffusion.github.io/},
}

@inproceedings{karnewar2023holofusion,
  title={Holofusion: Towards photo-realistic 3d generative modeling},
  author={Karnewar, Animesh and Mitra, Niloy J and Vedaldi, Andrea and Novotny, David},
  booktitle=iccv,
  pages={22976--22985},
  year={2023},
  projectpage={https://holodiffusion.github.io/holofusion/},
  link={https://arxiv.org/pdf/2308.14244},
}

@inproceedings{wang2023posediffusion,
  title={Posediffusion: Solving pose estimation via diffusion-aided bundle adjustment},
  author={Wang, Jianyuan and Rupprecht, Christian and Novotny, David},
  booktitle=iccv,
  pages={9773--9783},
  year={2023},
  projectpage={https://posediffusion.github.io/},
  link={https://arxiv.org/pdf/2306.15667.pdf},
}

@inproceedings{shapovalov2023replay,
  title={Replay: Multi-modal multi-view acted videos for casual holography},
  author={Shapovalov, Roman and Kleiman, Yanir and Rocco, Ignacio and Novotny, David and Vedaldi, Andrea and Chen, Changan and Kokkinos, Filippos and Graham, Ben and Neverova, Natalia},
  booktitle=iccv,
  pages={20338--20348},
  year={2023},
  projectpage={https://replay-dataset.github.io/},
  code={https://github.com/facebookresearch/replay_dataset},
  link={https://arxiv.org/pdf/2307.12067},
}

@inproceedings{hollein2024viewdiff,
  title={Viewdiff: 3d-consistent image generation with text-to-image models},
  author={Hollein, Lukas and Bozic, Aljaz and Muller, Norman and Novotny, David and Tseng, Hung-Yu and Richardt, Christian and Zollhofer, Michael and Niessner, Matthias},
  booktitle=cvpr,
  pages={5043--5052},
  year={2024},
  projectpage={https://lukashoel.github.io/ViewDiff/},
  code={https://github.com/facebookresearch/ViewDiff},
  link={https://arxiv.org/pdf/2403.01807},
}

@article{karnewar2024goembed,
  title={GOEmbed: Gradient Origin Embeddings for Representation Agnostic 3D Feature Learning},
  booktitle=eccv,
  year={2024},
  author={Karnewar, Animesh and Shapovalov, Roman and Monnier, Tom and Vedaldi, Andrea and Mitra, Niloy J and Novotny, David},
  projectpage={https://holodiffusion.github.io/goembed/},
  link={https://holodiffusion.github.io/goembed/static/docs/karnewar2023goembed.pdf},
}

@article{sabathier2024animal,
  title={Animal Avatars: Reconstructing Animatable 3D Animals from Casual Videos},
  author={Sabathier, Remy and Mitra, Niloy J and Novotny, David},
  journal=eccv,
  year={2024},
  note={Oral presentation},
  projectpage={https://remysabathier.github.io/animalavatar.github.io/},
  code={https://github.com/facebookresearch/AnimalAvatar},
  link={https://arxiv.org/abs/2403.17103},
}

@article{cao2024lightplane,
  title={Lightplane: Highly-Scalable Components for Neural 3D Fields},
  author={Cao, Ang and Johnson, Justin and Vedaldi, Andrea and Novotny, David},
  journal=arxiv,
  year={2024},
  projectpage={https://lightplane.github.io/},
  code={https://github.com/facebookresearch/lightplane},
  docs={https://lightplane.github.io/docs/index.html},
  link={https://arxiv.org/abs/2404.19760},
}

@article{wang2024vggsfm,
  title={Visual geometry grounded deep structure from motion},
  author={Wang, Jianyuan and Karaev, Nikita and Rupprecht, Christian and Novotny, David},
  journal=cvpr,
  year={2024},
  projectpage={https://vggsfm.github.io/},
  code={https://github.com/facebookresearch/vggsfm},
  link={https://arxiv.org/pdf/2312.04563},
  note={Spotlight presentation},
  extranote={IMC'24 winner},
}

@article{bensadoun2024meta,
  title={Meta 3D Gen},
  author={Bensadoun, Raphael and Monnier, Tom and Kleiman, Yanir and Kokkinos, Filippos and Siddiqui, Yawar and Kariya, Mahendra and Harosh, Omri and Shapovalov, Roman and Graham, Benjamin and Garreau, Emilien and Karnewar, Animesh and Cao, Ang and Azuri, Idan and Makarov, Iurii and Le, Eric-Tuan and Toisoul, Antoine and Novotny, David and Gafni, Oran and Neverova, Natalia and Vedaldi, Andrea},
  journal=arxiv,
  year={2024},
  link={https://arxiv.org/pdf/2407.02599},
}

@article{siddiqui2024meta,
  title={Meta 3D AssetGen: Text-to-Mesh Generation with High-Quality Geometry, Texture, and PBR Materials},
  author={Siddiqui, Yawar and Monnier, Tom and Kokkinos, Filippos and Kariya, Mahendra and Kleiman, Yanir and Garreau, Emilien and Gafni, Oran and Neverova, Natalia and Vedaldi, Andrea and Shapovalov, Roman and Novotny, David},
  journal=nips,
  year={2024},
  projectpage={https://assetgen.github.io/},
  link={https://assetgen.github.io/static/AssetGen.pdf},
}