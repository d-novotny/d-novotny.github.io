// TO ADD:

//   @article{ortiz2022isdf,
//     title={isdf: Real-time neural signed distance fields for robot perception},
//     author={Ortiz, Joseph and Clegg, Alexander and Dong, Jing and Sucar, Edgar and Novotny, David and Zollhoefer, Michael and Mukadam, Mustafa},
//     journal={arXiv preprint arXiv:2204.02296},
//     year={2022}
//   }
  
//   @inproceedings{avraham2022nerfels,
//     title={Nerfels: renderable neural codes for improved camera pose estimation},
//     author={Avraham, Gil and Straub, Julian and Shen, Tianwei and Yang, Tsun-Yi and Germain, Hugo and Sweeney, Chris and Balntas, Vasileios and Novotny, David and DeTone, Daniel and Newcombe, Richard},
//     booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
//     pages={5061--5070},
//     year={2022}
//   }
  
//   @inproceedings{germain2022feature,
//     title={Feature query networks: Neural surface description for camera pose refinement},
//     author={Germain, Hugo and DeTone, Daniel and Pascoe, Geoffrey and Schmidt, Tanner and Novotny, David and Newcombe, Richard and Sweeney, Chris and Szeliski, Richard and Balntas, Vasileios},
//     booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
//     pages={5071--5081},
//     year={2022}
//   }
  
//   @article{avrahamnerfels,
//     title={Nerfels: Renderable Neural Codes for Improved Camera Pose Estimation-Supplementary Material},
//     author={Avraham, Gil and Straub, Julian and Shen, Tianwei and Yang, Tsun-Yi and Germain, Hugo and Sweeney, Chris and Balntas, Vasileios and Novotny, David and DeTone, Daniel and Newcombe, Richard}
//   }
  
//   @inproceedings{novotny2022keytr,
//     title={Keytr: Keypoint transporter for 3d reconstruction of deformable objects in videos},
//     author={Novotny, David and Rocco, Ignacio and Sinha, Samarth and Carlier, Alexandre and Kerchenbaum, Gael and Shapovalov, Roman and Smetanin, Nikita and Neverova, Natalia and Graham, Benjamin and Vedaldi, Andrea},
//     booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
//     pages={5595--5604},
//     year={2022}
//   }
  
//   @article{germainsupplementary,
//     title={Supplementary Material Feature Query Networks: Neural Surface Description for Camera Pose Refinement},
//     author={Germain, Hugo and DeTone, Daniel and Pascoe, Geoffrey and Schmidt, Tanner and Novotny, David and Newcombe, Richard and Sweeney, Chris and Szeliski, Richard and Balntas, Vasileios}
//   }
  
//   @inproceedings{sinha2023common,
//     title={Common pets in 3d: Dynamic new-view synthesis of real-life deformable categories},
//     author={Sinha, Samarth and Shapovalov, Roman and Reizenstein, Jeremy and Rocco, Ignacio and Neverova, Natalia and Vedaldi, Andrea and Novotny, David},
//     booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
//     pages={4881--4891},
//     year={2023}
//   }
  
//   @inproceedings{el2023self,
//     title={Self-supervised correspondence estimation via multiview registration},
//     author={El Banani, Mohamed and Rocco, Ignacio and Novotny, David and Vedaldi, Andrea and Neverova, Natalia and Johnson, Justin and Graham, Ben},
//     booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
//     pages={1216--1225},
//     year={2023}
//   }
  
//   @article{elsupplementary,
//     title={Supplementary Material: Self-supervised Correspondence Estimation via Multiview Registration},
//     author={El Banani, Mohamed and Rocco, Ignacio and Novotny, David and Vedaldi, Andrea and Neverova, Natalia and Johnson, Justin and Graham, Ben}
//   }
  
//   @article{rocco2023real,
//     title={Real-time volumetric rendering of dynamic humans},
//     author={Rocco, Ignacio and Makarov, Iurii and Kokkinos, Filippos and Novotny, David and Graham, Benjamin and Neverova, Natalia and Vedaldi, Andrea},
//     journal={arXiv preprint arXiv:2303.11898},
//     year={2023}
//   }
  
//   @inproceedings{karnewar2023holodiffusion,
//     title={Holodiffusion: Training a 3d diffusion model using 2d images},
//     author={Karnewar, Animesh and Vedaldi, Andrea and Novotny, David and Mitra, Niloy J},
//     booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
//     pages={18423--18433},
//     year={2023}
//   }
  
//   @inproceedings{wang2023posediffusion,
//     title={Posediffusion: Solving pose estimation via diffusion-aided bundle adjustment},
//     author={Wang, Jianyuan and Rupprecht, Christian and Novotny, David},
//     booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
//     pages={9773--9783},
//     year={2023}
//   }
  
//   @inproceedings{shapovalov2023replay,
//     title={Replay: Multi-modal multi-view acted videos for casual holography},
//     author={Shapovalov, Roman and Kleiman, Yanir and Rocco, Ignacio and Novotny, David and Vedaldi, Andrea and Chen, Changan and Kokkinos, Filippos and Graham, Ben and Neverova, Natalia},
//     booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
//     pages={20338--20348},
//     year={2023}
//   }
  
//   @inproceedings{karnewar2023holofusion,
//     title={Holofusion: Towards photo-realistic 3d generative modeling},
//     author={Karnewar, Animesh and Mitra, Niloy J and Vedaldi, Andrea and Novotny, David},
//     booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
//     pages={22976--22985},
//     year={2023}
//   }
  
//   @article{karnewarholofusion,
//     title={HOLOFUSION: Towards Photo-realistic 3D Generative Modeling Supplementary Material},
//     author={Karnewar, Animesh and Mitra, Niloy J and Vedaldi, Andrea and Novotny, David}
//   }
  
//   @article{wang2023visual,
//     title={Visual geometry grounded deep structure from motion},
//     author={Wang, Jianyuan and Karaev, Nikita and Rupprecht, Christian and Novotny, David},
//     journal={arXiv preprint arXiv:2312.04563},
//     year={2023}
//   }
  
//   @article{karnewar2023goenfusion,
//     title={GOEnFusion: Gradient Origin Encodings for 3D Forward Diffusion Models},
//     author={Karnewar, Animesh and Vedaldi, Andrea and Mitra, Niloy J and Novotny, David},
//     journal={arXiv preprint arXiv:2312.08744},
//     year={2023}
//   }
  
//   @inproceedings{hollein2024viewdiff,
//     title={Viewdiff: 3d-consistent image generation with text-to-image models},
//     author={H{\"o}llein, Lukas and M{\"u}ller, Norman and Novotny, David and Tseng, Hung-Yu and Richardt, Christian and Zollh{\"o}fer, Michael and Nie{\ss}ner, Matthias and others},
//     booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
//     pages={5043--5052},
//     year={2024}
//   }
  
//   @article{sabathier2024animal,
//     title={Animal Avatars: Reconstructing Animatable 3D Animals from Casual Videos},
//     author={Sabathier, Remy and Mitra, Niloy J and Novotny, David},
//     journal={arXiv preprint arXiv:2403.17103},
//     year={2024}
//   }
  
//   @article{cao2024lightplane,
//     title={Lightplane: Highly-Scalable Components for Neural 3D Fields},
//     author={Cao, Ang and Johnson, Justin and Vedaldi, Andrea and Novotny, David},
//     journal={arXiv preprint arXiv:2404.19760},
//     year={2024}
//   }
  
//   @inproceedings{wang2024vggsfm,
//     title={VGGSfM: Visual Geometry Grounded Deep Structure From Motion},
//     author={Wang, Jianyuan and Karaev, Nikita and Rupprecht, Christian and Novotny, David},
//     booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
//     pages={21686--21697},
//     year={2024}
//   }
  
//   @article{siddiqui2024meta,
//     title={Meta 3D AssetGen: Text-to-Mesh Generation with High-Quality Geometry, Texture, and PBR Materials},
//     author={Siddiqui, Yawar and Monnier, Tom and Kokkinos, Filippos and Kariya, Mahendra and Kleiman, Yanir and Garreau, Emilien and Gafni, Oran and Neverova, Natalia and Vedaldi, Andrea and Shapovalov, Roman and others},
//     journal={arXiv preprint arXiv:2407.02445},
//     year={2024}
//   }
  
//   @article{bensadoun2024meta,
//     title={Meta 3D Gen},
//     author={Bensadoun, Raphael and Monnier, Tom and Kleiman, Yanir and Kokkinos, Filippos and Siddiqui, Yawar and Kariya, Mahendra and Harosh, Omri and Shapovalov, Roman and Graham, Benjamin and Garreau, Emilien and others},
//     journal={arXiv preprint arXiv:2407.02599},
//     year={2024}
//   }


bib_data = {

//   @inproceedings{avraham2022nerfels,
//     title={Nerfels: renderable neural codes for improved camera pose estimation},
//     author={Avraham, Gil and Straub, Julian and Shen, Tianwei and Yang, Tsun-Yi and Germain, Hugo and Sweeney, Chris and Balntas, Vasileios and Novotny, David and DeTone, Daniel and Newcombe, Richard},
//     booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
//     pages={5061--5070},
//     year={2022}
//   }
  
//   @inproceedings{germain2022feature,
//     title={Feature query networks: Neural surface description for camera pose refinement},
//     author={Germain, Hugo and DeTone, Daniel and Pascoe, Geoffrey and Schmidt, Tanner and Novotny, David and Newcombe, Richard and Sweeney, Chris and Szeliski, Richard and Balntas, Vasileios},
//     booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
//     pages={5071--5081},
//     year={2022}
//   }

    "ortiz2022isdf": {
        "title": "isdf: Real-time neural signed distance fields for robot perception",
        "author": "Ortiz, J. and Clegg, A. and Dong, J. and Sucar, E. and Novotny, D. and Zollhoefer, M. and Mukadam, M.",
        "journal": "RSS 2022",
        "buttons": {
            "code": ["https://github.com/facebookresearch/iSDF", "fa fa-code"],
            "project page": ["https://github.com/facebookresearch/iSDF", "fa fa-lightbulb-o"],
            "talk": ["https://www.youtube.com/watch?v=mAKGl1wBSic&ab_channel=JosephOrtiz", "fa fa-video-camera"],
        }
    },
    "shapovalov2021densepose": {
        "title": "DensePose 3D: Lifting canonical surface maps of articulated objects to the third dimension",
        "author": "Shapovalov, R. and Novotny, D. and Graham, B. and Labatut, P. and Vedaldi, A.",
        "journal": "ICCV 2021",
        "note": "oral presentation",
    },
    "reizenstein21co3d": {
        "author": "Reizenstein, J. and Shapovalov, R. and Henzler, P. and Sbordone, L. and Labatut, P. and Novotny, D.",
        "title": "Common Objects in 3D: Large-Scale Learning and Evaluation of Real-life 3D Category Reconstruction",
        "journal": "ICCV 2021",
        "note": "oral presentation",
        "extra_note": "Best Paper Honorable Mention",
        "is_gif_thumb": true,
        "buttons": {
            "code": ["https://github.com/facebookresearch/co3d", "fa fa-code"],
            "project page": ["https://ai.facebook.com/datasets/CO3D-dataset/", "fa fa-lightbulb-o"],
            "talk": ["https://www.youtube.com/watch?v=hMx9nzG50xQ", "fa fa-video-camera"]
        }
    },
    "henzler21unsupervised": {
        "author": "Henzler, P. and Reizenstein, J. and Labatut, P. and Shapovalov, R. and Ritschel, T. and Vedaldi, A. and Novotny, D.",
        "title": "Unsupervised Learning of 3D Object Categories from Videos in the Wild",
        "journal": "CVPR 2021",
        "buttons": {
            "talk": ["https://youtu.be/910z84dldEU", "fa fa-video-camera"]
        }
    },
    "eisenberger21neuromorph": {
        "author": "Eisenberger, M. and Novotny, D. and Kerchenbaum, G. and Labatut, P. and Neverova, N. and Cremers, D. and Vedaldi, A.",
        "title": "NeuroMorph: Unsupervised Shape Interpolation and Correspondence in One Go",
        "journal": "CVPR 2021",
        "is_gif_thumb": true,
    },
    "biggs203dmulti": {
        "author": "Biggs, B. and Ehrhadt, S. and Joo, H. and Graham, B. and Vedaldi, A. and Novotny, D.",
        "title": "3D Multi-bodies: Fitting Sets of Plausible 3D Human Models to Ambiguous Image Data",
        "journal": "NeurIPS 2020",
        "note": "spotlight presentation",
        "buttons": {
            "project page": ["https://sites.google.com/view/3dmb/home", "fa fa-lightbulb-o"],
            "talk": ["https://youtu.be/uSvswzbQ-Q8", "fa fa-video-camera"]
        }
    },
    "graham20ridgesfm": {
        "author": "Graham, B. and Novotny, D.",
        "title": "RidgeSfM: Structure from Motion via Robust Pairwise Matching Under Depth Uncertainty",
        "journal": "3DV 2020",
        "buttons": {
            "code": ["https://github.com/facebookresearch/RidgeSfM", "fa fa-code"]
        }
    },
    "novotny20c3dm": {
        "author": "Novotny, D.* and Shapovalov, R.* and Vedaldi, A.",
        "title": "Canonical 3D Deformer Maps: Unifying Parametric and Non-parametric Methods for Dense Weakly-supervised Category Reconstruction",
        "journal": "NeurIPS 2020",
        "buttons": {
            "code": ["https://github.com/facebookresearch/c3dm", "fa fa-code"]
        }
    },
    "neverova20cse": {
        "author": "Neverova, N. and Novotny, D. and Khalidov, V. and Szafraniec, M. and Labatut, P. and Vedaldi, A.",
        "title": "Continuous Surface Embeddings",
        "journal": "NeurIPS 2020"
    },
    "novotny19perspectivenet": {
        "author": "Novotny, D. and Graham, B. and Reizenstein, J.",
        "title": "PerspectiveNet: A Scene-consistent Image Generator for New View Synthesis in Real Indoor Environments",
        "journal": "NeurIPS 2019"
    },
    "novotny19c3dpo": {
        "author": "Novotny, D.* and Ravi, N.* and Graham, B. and Neverova, N. and Vedaldi, A.",
        "title": "C3DPO: Canonical 3D Pose Networks for Non-Rigid Structure From Motion",
        "journal": "ICCV 2019",
        "note": "oral presentation",
        "is_gif_thumb": true,
        "buttons": {
            "code": ["https://github.com/facebookresearch/c3dpo_nrsfm", "fa fa-code"],
            "talk": ["https://youtu.be/zem03fZWLrQ?t=2303", "fa fa-video-camera"]
        }
    },
    "novotny18capturing": {
        "author": "Novotny, D. and Larlus, D. and Vedaldi, A.",
        "title": "Capturing the Geometry of Object Categories from Video Supervision",
        "journal": "TPAMI 2018",
        "is_gif_thumb": true,
    },
    "novotny18semi": {
        "author": "Novotny, D.* and Albanie, S.* and Larlus, D. and Vedaldi, A.",
        "title": "Semi-convolutional Operators for Instance Segmentation",
        "journal": "ECCV 2018"
    },
    "novotny18self": {
        "author": "Novotny, D.* and Albanie, S.* and Larlus, D. and Vedaldi, A.",
        "title": "Self-supervised Learning of Geometrically Stable Features Through Probabilistic Introspection",
        "journal": "CVPR 2018",
        "note": "spotlight presentation",
        "buttons": {
            "talk": ["https://www.facebook.com/CVPR2018/videos/1994396307555935/", "fa fa-video-camera"]
        }
    },
    "novotny17learning": {
        "author": "Novotny, D. and Larlus, D. and Vedaldi, A.",
        "title": "Learning 3D Object Categories by Looking Around Them",
        "journal": "ICCV 2017",
        "note": "oral presentation",
        "buttons": {
            "talk": ["https://www.youtube.com/watch?v=esYBbQuKFZU&t=", "fa fa-video-camera"]
        }
    },
    "novotny17anchornet": {
        "author": "Novotny, D. and Larlus, D. and Vedaldi, A.",
        "title": "AnchorNet: A Weakly Supervised Network to Learn Geometry-sensitive Features For Semantic Matching",
        "journal": "CVPR 2017",
        "buttons": {
            "code": ["code/anchornet_code_v0.1.zip", "fa fa-code"]
        }
    },
    "novotny16ihave": {
        "author": "Novotny, D. and Larlus, D. and Vedaldi, A.",
        "title": "I Have Seen Enough: Transferring Parts Across Categories",
        "journal": "BMVC 2016",
        "buttons": {
            "dataset": ["http://www.robots.ox.ac.uk/~vgg/data/animal_parts/", "fa fa-database"]
        }
    },
    "novotny16learning": {
        "author": "Novotny, D. and Larlus, D. and Vedaldi, A.",
        "title": "Learning the Structure of Objects from Web Supervision",
        "journal": "ECCV 2016 Workshops"
    },
    "novotny15cascaded": {
        "author": "Novotny, D. and Matas, J.",
        "title": "Cascaded Sparse Spatial Bins for Efficient and Effective Generic Object Detection",
        "journal": "ICCV 2015",
        "buttons": {
            "video": ["goodies/iccv15spotlight.mp4", "fa fa-picture-o"]
        }
    }
}


for (const paper_id in bib_data) {
    // console.log(`${paper_id}: ${bib_data[paper_id]}`);
    paper_entry = bib_data[paper_id];

    // make the div for the paper entry
    const div = document.createElement('div');
    div.className = "row 100% uniform";

    innerHTML = "";

    // make thumbnail
    thumb_extension = paper_entry["is_gif_thumb"] ? "gif" : "png";
    thumb_path = "paper_thumbs/thumb_" + paper_id + "." + thumb_extension;
    innerHTML += `<div class="4u"><span class="image fit"><img src="${thumb_path}" alt="" /></span></div>`;
    
    // make author field
    author_string = paper_entry["author"]
    innerHTML += `<div class="8u"><p><i>${author_string}</i><br>`;
    
    // make title field
    title_string = paper_entry["title"]
    innerHTML += `<strong class="hoverable">${title_string}</strong></br>`

    // add extra fields
    journal_string = paper_entry["journal"]
    innerHTML += `${journal_string}`
    if ("note" in paper_entry){
        note_string = paper_entry["note"]
        innerHTML += `, ${note_string}`
    }
    if ("extra_note" in paper_entry){
        extra_note_string = paper_entry["extra_note"]
        innerHTML += `, <strong style="color:#8BBE6A">${extra_note_string}</strong>`
    }
    innerHTML += `<br>`

    // paper button
    paper_file = `papers/${paper_id}.pdf`
    innerHTML += `<a href=${paper_file} class="button tiny"><i class="fa fa-file-pdf-o" aria-hidden="true"></i>&nbsp pdf</a>`;

    // other buttons
    if ("buttons" in paper_entry) {
        buttons = paper_entry["buttons"]
        for (const button in buttons) {
            link = buttons[button][0]
            icon = buttons[button][1]
            innerHTML += `<a href="${link}" class="button tiny"><i class="${icon}" aria-hidden="true"></i>&nbsp ${button}</a>`;
        }
    }

    innerHTML += `</div>`;

    div.innerHTML = innerHTML

    document.getElementById('publist').appendChild(div);

    // document.body.getElementById('publist').appendChild(div);

}								
